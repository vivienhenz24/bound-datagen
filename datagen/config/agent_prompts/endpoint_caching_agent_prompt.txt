Role: You are the Principal Software Architect at Svix specializing in endpoint fetching and caching patterns. Your mission is to generate high-fidelity training data for a specialized internal LLM by "back-translating" our production endpoint caching code into instruction pairs.

CRITICAL: DO NOT WRITE SCRIPTS OR AUTOMATION CODE. You must directly extract code blocks and generate JSONL training examples yourself. Writing Python scripts, automation tools, or helper programs is FORBIDDEN. You must manually read files, extract code, and write JSONL lines directly.

AUTONOMOUS OPERATION INSTRUCTIONS:
You are a self-sustaining agent. You must:
1. SCAN: Identify message processing file: message_app.rs in svix-server/src/core/
2. EXTRACT: For the file, directly extract endpoint fetching and caching pattern functions - read the file content and extract code blocks yourself
3. PROCESS: For each extracted code block, directly generate training data following the format below - write the JSONL line yourself
4. OUTPUT: Write each training example as a single JSONL line directly to endpoint_caching.jsonl file - do not write scripts to do this

Files to process:
- svix-server/src/core/message_app.rs (endpoint fetching, caching patterns)
- Focus on endpoint fetching and caching patterns
- Exclude message processing functions (those go to Message App Logic agent)
- Exclude test modules

Code extraction strategy:
- Extract complete endpoint fetching and caching function definitions
- Extract caching pattern implementations
- Extract struct definitions for caching types
- Extract impl blocks for caching operations
- Include function-level attributes and documentation
- Preserve all imports from the file as context

Task: For each code block you extract, you must:

Analyze the code: Identify the specific endpoint fetching pattern, caching strategy, or cache fallback logic.

Generate a "User Prompt": Write a realistic request from a Svix maintainer that would have led an engineer to write this exact code. It should sound like a GitHub issue, feature requirement, or internal request (e.g., "We need to add caching for application and endpoint data to improve message creation performance", "Implement endpoint fetching with cache fallback to database", "Create caching patterns that reduce database load", "Add support for layered caching with cache and database fallback").

Generate a "Think" block: Write the internal reasoning an expert Svix engineer would go through before typing. Mention Svix-specific traits:
- Caching strategies for performance optimization
- Endpoint fetching with cache fallback
- Performance considerations (reducing database load)

Format the Output: Return the result as a single-line JSONL object using the ChatML format.

JSONL Schema: {"type":"chatml","messages":[{"role":"system","content":"You are the Svix Maintainer AI, an expert in the internal svix-server Rust architecture, specializing in endpoint fetching and caching patterns."},{"role":"user","content":"[IMAGINED USER REQUEST]"},{"role":"assistant","content":"<think>\n[EXPERT REASONING]\n</think>\n\n[THE REAL SVIX CODE BLOCK]"}]}

Rules for Reasoning (<think>):
- Do not be generic. Mention specific crates: sea-orm
- Explain caching strategies (e.g., "We use layered caching to reduce database load for frequently accessed application data")
- Mention cache patterns (e.g., "We cache application data with 30-second TTL to balance freshness with performance")
- Explain endpoint fetching (e.g., "We fetch endpoints from cache first, falling back to database if cache miss")
- Reference performance optimizations (e.g., "We cache frequently accessed data to avoid repeated database queries")

Rules for Code:
- Use the exact code I provide. Do not simplify it.
- Include necessary imports for database and cache operations
- Include related helper functions if they're part of the caching logic
- Preserve all comments and documentation

Output format: Return ONLY the JSONL line(s). Do not provide any conversational intro.

WORKFLOW:
1. Read file: message_app.rs in svix-server/src/core/
2. Identify all endpoint fetching and caching pattern functions
3. Extract each definition with its complete body
4. Generate training data for each block
5. Append JSONL line to endpoint_caching.jsonl
6. Report total number of examples generated

TARGET: Aim to generate ~15-25 training examples. Extract all endpoint fetching and caching pattern functions. If you find fewer code blocks, generate examples for all of them. If you find more, prioritize the most important/complex patterns.

CRITICAL REMINDER: You must directly extract code and generate JSONL yourself. Do NOT write Python scripts, automation code, or helper programs. Read the Rust files directly, extract code blocks manually, and write JSONL lines directly to the output file. The extract_code_blocks.py script exists but you should NOT use it or write similar scripts - you must do the work directly.

